{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ~/venv-ptmetal/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torchvision\n",
      "Version: 0.16.1\n",
      "Summary: image and video datasets and models for torch deep learning\n",
      "Home-page: https://github.com/pytorch/vision\n",
      "Author: PyTorch Core Team\n",
      "Author-email: soumith@pytorch.org\n",
      "License: BSD\n",
      "Location: /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages\n",
      "Requires: numpy, pillow, requests, torch\n",
      "Required-by: \n",
      "Requirement already satisfied: torchvision in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (0.16.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.16.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from torchvision) (2.31.0)\n",
      "Collecting torch==2.1.2 (from torchvision)\n",
      "  Downloading torch-2.1.2-cp39-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: filelock in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from torch==2.1.2->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from torch==2.1.2->torchvision) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from torch==2.1.2->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from torch==2.1.2->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from torch==2.1.2->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from torch==2.1.2->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from jinja2->torch==2.1.2->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from sympy->torch==2.1.2->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.16.2-cp39-cp39-macosx_11_0_arm64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.2-cp39-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.1\n",
      "    Uninstalling torch-2.1.1:\n",
      "      Successfully uninstalled torch-2.1.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.16.1\n",
      "    Uninstalling torchvision-0.16.1:\n",
      "      Successfully uninstalled torchvision-0.16.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.1.2 torchvision-0.16.2\n"
     ]
    }
   ],
   "source": [
    "!pip show torchvision && pip install torchvision --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device for GPU acceleration!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(\"Using MPS device for GPU acceleration!\")\n",
    "else:\n",
    "    print(\"MPS device not found. Falling back to CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Time:  0.29730987548828125\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.mps.synchronize()\n",
    "a = torch.ones(4000,4000).to(device)\n",
    "for _ in range(500):\n",
    "   a +=a\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print( \"GPU Time: \", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n"
     ]
    }
   ],
   "source": [
    "!curl -o model.h5 https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -O model.h5 https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml==5.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (5.1)\n",
      "fatal: destination path 'detectron2' already exists and is not an empty directory.\n",
      "Requirement already satisfied: Pillow>=7.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (10.1.0)\n",
      "Requirement already satisfied: matplotlib in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (3.8.1)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (2.0.7)\n",
      "Requirement already satisfied: termcolor>=1.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (2.1.1)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (0.1.8)\n",
      "Requirement already satisfied: tabulate in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (0.9.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (3.0.0)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (4.65.0)\n",
      "Requirement already satisfied: tensorboard in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (2.10.1)\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (0.1.5.post20221221)\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (0.1.9)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (2.3.0)\n",
      "Requirement already satisfied: hydra-core>=1.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (1.3.2)\n",
      "Requirement already satisfied: black in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (23.11.0)\n",
      "Requirement already satisfied: packaging in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (23.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from matplotlib) (5.10.1)\n",
      "Requirement already satisfied: PyYAML in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from yacs>=0.1.8) (5.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from tensorboard) (1.3.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from tensorboard) (1.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from tensorboard) (2.14.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from tensorboard) (3.19.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from tensorboard) (65.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from tensorboard) (0.37.1)\n",
      "Requirement already satisfied: portalocker in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from iopath<0.1.10,>=0.1.7) (2.8.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from omegaconf<2.4,>=2.1) (4.9.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from black) (8.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from black) (1.0.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from black) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from black) (3.1.1)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from black) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from black) (4.8.0)\n",
      "Requirement already satisfied: six in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.11.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard) (5.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pyyaml==5.1\n",
    "import sys, os, distutils.core\n",
    "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
    "!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  2.1 ; cuda:  2.1.2\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing MLIR with module: _site_initialize_0\n",
      "Registering dialects from initializer <module 'jaxlib.mlir._mlir_libs._site_initialize_0' from '/Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages/jaxlib/mlir/_mlir_libs/_site_initialize_0.so'>\n",
      "etils.epath found. Using etils.epath for file I/O.\n",
      "Using MPS device for GPU acceleration!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m     frame_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(rgb_frame)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m frame_tensor\n\u001b[0;32m---> 58\u001b[0m model_tf \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39m[layer\u001b[38;5;241m.\u001b[39mto(nn\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model_tf\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model_tf\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrcnn_mask_head_fc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.fft import fft2, ifft2\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "from torch.nn import DataParallel\n",
    "from torchvision.models import resnet50\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(\"Using MPS device for GPU acceleration!\")\n",
    "else:\n",
    "    print(\"MPS device not found. Falling back to CPU.\")\n",
    "\n",
    "def farneback_mps(I1, I2, pyr_levels, eps, tol):\n",
    "    Ix1, Iy1 = _compute_derivatives(I1)\n",
    "    Ix2, Iy2 = _compute_derivatives(I2)\n",
    "    flow = torch.zeros_like(Ix1)\n",
    "    for level in range(pyr_levels):\n",
    "        warped_I2 = _warp_image(I2, flow * 2 ** level)\n",
    "        diff = warped_I2 - I1\n",
    "        Ixx, Iyy = _compute_derivatives(diff)\n",
    "        error = torch.sqrt(Ixx**2 + Iyy**2)\n",
    "        flow = _update_flow(flow, Ix1, Iy1, Ixx, Iyy, error, eps, tol)\n",
    "    flow = flow / 2 ** (pyr_levels - 1)\n",
    "    return flow\n",
    "\n",
    "def _compute_derivatives(image):\n",
    "    sobel_x = torch.tensor([-1, 0, 1, -2, 0, 2, -1, 0, 1]).view(3, 3).to(\"mps\")\n",
    "    sobel_y = torch.tensor([1, 2, 1, 0, 0, 0, -1, -2, -1]).view(3, 3).to(\"mps\")\n",
    "    Ix = F.conv2d(image, sobel_x, padding=1, groups=3).to(\"mps\")\n",
    "    Iy = F.conv2d(image, sobel_y, padding=1, groups=3).to(\"mps\")\n",
    "    return Ix, Iy\n",
    "\n",
    "def _warp_image(image, flow):\n",
    "    flow_x, flow_y = flow.split(2, dim=1)\n",
    "    grid_x, grid_y = F.affine_grid(flow, image.shape, align_corners=False)\n",
    "    warped_image = F.grid_sample(image, torch.stack([grid_x, grid_y], dim=3), mode=\"bilinear\", padding_mode=\"border\", align_corners=False).to(\"mps\")\n",
    "    return warped_image\n",
    "\n",
    "def _update_flow(flow, Ix1, Iy1, Ixx, Iyy, error, eps, tol):\n",
    "    flow_dx = F.conv2d(flow, Ixx, padding=1).to(\"mps\")\n",
    "    flow_dy = F.conv2d(flow, Iyy, padding=1).to(\"mps\")\n",
    "    flow -= (Ix1 * flow_dx + Iy1 * flow_dy) / (error**2 + eps)\n",
    "    smooth_flow = F.conv2d(flow, torch.ones((3, 3)).to(\"mps\"), padding=1).to(\"mps\")\n",
    "    flow = (1 - tol) * flow + tol * smooth_flow\n",
    "    return flow\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    resized_frame = cv2.resize(frame, (800, 600))\n",
    "    normalized_frame = resized_frame / 255.0\n",
    "    rgb_frame = cv2.cvtColor(normalized_frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_tensor = torch.from_numpy(rgb_frame).permute(2, 0, 1).to(device)\n",
    "    return frame_tensor\n",
    "\n",
    "model_tf = load_model(\"model.h5\")\n",
    "model = nn.Sequential(*[layer.to(nn.device) for layer in model_tf.layers])\n",
    "for name, param in model_tf.get_layer(\"mrcnn_mask_head_fc\").items():\n",
    "    model_torch.state_dict()[name].copy_(param)\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"installing\")\n",
    "import requests\n",
    "print(\"Model loaded and moved to device.\")\n",
    "\n",
    "def calculate_segment_velocity(segment, prev_frame, current_frame):\n",
    "    mask = masks[segment]\n",
    "    masked_prev_frame = prev_frame * mask\n",
    "    masked_current_frame = current_frame * mask\n",
    "    segment_flow = farneback_mps(masked_prev_frame, masked_current_frame, pyr_levels=3, eps=0.01, tol=0.5)\n",
    "    segment_velocity = torch.sum(segment_flow) / torch.sum(mask)\n",
    "    return segment_velocity.cpu().numpy()\n",
    "\n",
    "def visualize_results(frame, segments, masks, velocities):\n",
    "    for segment, mask, bbox, velocity in zip(segments, masks, segment_boxes, velocities):\n",
    "        cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[0] + bbox[2], bbox[1] + bbox[3]), (0, 255, 0), 2)\n",
    "        start_point = (int(bbox[0] + bbox[2]/2), int(bbox[1] + bbox[3]/2))\n",
    "        end_point = (start_point[0] + int(velocity[0]), start_point[1] + int(velocity[1]))\n",
    "        cv2.arrowedLine(frame, start_point, end_point, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "cap = cv2.VideoCapture(\"video.mp4\")\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    prev_frame = preprocess_frame(prev_frame)\n",
    "    current_frame = preprocess_frame(frame)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(current_frame.unsqueeze(0))\n",
    "        segments = predictions[0].cpu().numpy()\n",
    "        masks = predictions[1].cpu().numpy()\n",
    "\n",
    "    velocities = []\n",
    "    for segment in segments:\n",
    "        segment_velocity = calculate_segment_velocity(segment, prev_frame, current_frame)\n",
    "        velocities.append(segment_velocity)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 frames completed\n",
      "10 frames completed\n",
      "20 frames completed\n",
      "30 frames completed\n",
      "40 frames completed\n",
      "50 frames completed\n",
      "60 frames completed\n",
      "70 frames completed\n",
      "80 frames completed\n",
      "90 frames completed\n",
      "100 frames completed\n",
      "110 frames completed\n",
      "120 frames completed\n",
      "130 frames completed\n",
      "140 frames completed\n",
      "150 frames completed\n",
      "160 frames completed\n",
      "170 frames completed\n",
      "180 frames completed\n",
      "190 frames completed\n",
      "200 frames completed\n",
      "210 frames completed\n",
      "220 frames completed\n",
      "230 frames completed\n",
      "240 frames completed\n",
      "250 frames completed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    resized_frame = cv2.resize(frame, (800, 600))\n",
    "    normalized_frame = resized_frame / 255.0\n",
    "    rgb_frame = cv2.normalize(normalized_frame, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2RGB)\n",
    "    return rgb_frame\n",
    "\n",
    "def draw_optical_flow_hsv(flow):\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv = np.zeros_like(frame)\n",
    "    hsv[..., 1] = 255\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return bgr\n",
    "\n",
    "def draw_optical_flow(frame, flow):\n",
    "    h, w = frame.shape[:2]\n",
    "    step = 16\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2,-1).astype(int)\n",
    "    fx, fy = flow[y,x].T\n",
    "    vis = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "    for (x, y), (fx, fy) in zip(np.stack([x, y], axis=-1), np.stack([fx, fy], axis=-1)):\n",
    "        cv2.line(vis, (x, y), (x+int(fx), y+int(fy)), (0, 255, 0), 1)\n",
    "        cv2.circle(vis, (x, y), 1, (0, 255, 0), -1)\n",
    "    return vis\n",
    "\n",
    "def stack_frames(original_frame, processed_frame):\n",
    "    processed_resized = cv2.resize(processed_frame, (original_frame.shape[1], original_frame.shape[0]))\n",
    "    stacked_frame = np.hstack((original_frame, processed_resized))\n",
    "    return stacked_frame\n",
    "\n",
    "cap = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print(\"Error: Could not open video file\")\n",
    "    exit()\n",
    "\n",
    "prev_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "frames_for_gif = []\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if (i % 10 == 0):\n",
    "        print(i, \"frames completed\")\n",
    "    i += 1\n",
    "\n",
    "    frame = preprocess_frame(frame)\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_gray = cv2.resize(prev_gray, (gray.shape[1], gray.shape[0]))\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    flow_hsv = draw_optical_flow_hsv(flow)\n",
    "\n",
    "    stacked = stack_frames(frame, flow_hsv)\n",
    "    stacked = cv2.cvtColor(stacked, cv2.COLOR_BGR2RGB)\n",
    "    frames_for_gif.append(stacked)\n",
    "\n",
    "    prev_gray = gray\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "imageio.mimsave('output.gif', frames_for_gif, duration=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
